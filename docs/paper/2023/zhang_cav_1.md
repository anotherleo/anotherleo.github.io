# QEBVerif: Quantization Error Bound Verification of Neural Networks

<center>Yedi Zhang, Fu Song, and Jun Sun</center>

To alleviate the practical constraints for deploying deep neural networks (DNNs) on edge devices, quantization is widely regarded as one promising technique. It reduces the resource requirements for computational power and storage space by quantizing the weights and/or activation tensors of a DNN into lower bit-width fixed-point numbers, resulting in quantized neural networks (QNNs). While it has been empirically shown to introduce minor accuracy loss, critical verified properties of a DNN might become invalid once quantized. Existing verification methods focus on either individual neural networks (DNNs or QNNs) or quantization error bound for partial quantization. 

In this work, we propose a quantization error bound verification method, named QEBVerif, where both weights and activation tensors are quantized. QEBVerif consists of two parts, i.e., a differential reachability analysis (DRA) and a mixed-integer linear programming (MILP) based verification method. DRA performs difference analysis between the DNN and its quantized counterpart layer-by-layer to compute a tight quantization error interval eﬃciently. If DRA fails to prove the error bound, then we encode the verification problem into an equivalent MILP problem which can be solved by off-the-shelf solvers. Thus, QEBVerif is sound, complete, and reasonably eﬃcient. We implement QEBVerif and conduct extensive experiments, showing its effectiveness and eﬃciency.

## Introduction

In the past few years, the development of deep neural networks (DNNs) has grown at an impressive pace owing to their outstanding performance in solving various complicated tasks [23,28]. However, modern DNNs are often large in size and contain a great number of 32-bit floating-point parameters to achieve competitive performance. Thus, they often result in high computational costs and excessive storage requirements, hindering their deployment on resource-constrained embedded devices, e.g., edge devices. A promising solution is to quantize the weights and/or activation tensors as fixed-point numbers of lower bit-width [17,21,25,35]. For example, TensorFlow Lite [18] supports quantization of weights and/or activation tensors to reduce the model size and latency, and Tesla FSD-chip [61] stores all the data and weights of a network in the form of 8-bit integers.

In spite of the empirically impressive results which show there is only minor accuracy loss, quantization does not necessarily preserve properties such as robustness [16]. Even worse, input perturbation can be amplified by quantization [11,36], worsening the robustness of quantized neural networks (QNNs) compared to their DNN counterparts. Indeed, existing neural network quantization methods focus on minimizing its impact on model accuracy (e.g., by formulating it as an optimization problem that aims to maximize the accuracy [27,43]). However, they cannot guarantee that the final quantization error is always lower than a given error bound, especially when some specific safety-critical input regions are concerned. This is concerning as such errors may lead to catastrophes when the quantized networks are deployed in safety-critical applications [14,26]. Furthermore, analyzing (in particular, quantifying) such errors can also help us understand how quantization affect the network behaviors [33], and provide insights on, for instance, how to choose appropriate quantization bit sizes without introducing too much error. Therefore, a method that soundly quantifies the errors between DNNs and their quantized counterparts is highly desirable.

There is a large and growing body of work on developing verification methods for DNNs [2,12,13,15,19,24,29,30,32,37,38,51,54,55,58–60,62] and QNNs [1,3,16,22,46,66,68], aiming to establish a formal guarantee on the network behaviors. However, all the above-mentioned methods focus exclusively on verifying individual neural networks. Recently, Paulsen et al. [48,49] proposed differential verification methods, aimed to establish formal guarantees on the difference between two DNNs. Specifically, given two DNNs N1 and N2 with the same network topology and inputs, they try to prove that |N1(x) − N2(x)| < ϵ for all possible inputs x ∈ X, where X is the interested input region. They presented fast and sound difference propagation techniques followed by a refinement of the input region until the property can be successfully verified, i.e., the property is either proved or falsified by providing a counterexample. This idea has been extended to handle recurrent neural networks (RNNs) [41] though the refinement is not considered therein. Although their methods [41,48,49] can be used to analyze the error bound introduced by quantizing weights (called partially QNNs), they are not complete and cannot handle the cases where both the weights and activation tensors of a DNN are quantized to lower bit-width fixed-point numbers (called fully QNNs). We remark that fully QNN can significantly reduce the energy-consumption (floating-point operations consume much more energy than integer-only operations) [61].

Main Contributions. We propose a sound and complete Quantization Error Bound Verification method (QEBVerif) to eﬃciently and effectively verify if the quantization error of a fully QNN w.r.t. an input region and its original DNN is always lower than an error bound (a.k.a. robust error bound [33]). QEBVerif first conducts a novel reachability analysis to quantify the quantization errors, which is referred to as differential reachability analysis (DRA). Such an analysis yields two results: (1) Proved, meaning that the quantization error is proved to be always less than the given error bound; or (2) Unknown, meaning that it fails to prove the error bound, possibly due to a conservative approximation of the quantization error. If the outcome is Unknown, we further encode this quantization error bound verification problem into an equivalent mixed-integer linear programming (MILP) problem, which can be solved by off-the-shelf solvers.

There are two main technical challenges that must be addressed for DRA. First, the activation tensors in a fully QNN are discrete values and contribute additional rounding errors to the final quantization errors, which are hard to propagate symbolically and make it diﬃcult to establish relatively accurate difference intervals. Second, much more activation-patterns (i.e., 3 × 6 = 18) have to consider in a forward propagation, while 9 activation-patterns are suﬃcient in [48,49], where an activation-pattern indicates the status of the output range of a neuron. A neuron in a DNN under an input region has 3 patterns: always-active (i.e., output ≥ 0), always-inactive (i.e., output < 0), or both possible. A neuron in a QNN has 6 patterns due to the clamp function (cf. Definition 2). We remark that handling these different combinations eﬃciently and soundly is highly nontrivial. To tackle the above challenges, we propose sound transformations for the aﬃne and activation functions to propagate quantization errors of two networks layer-by-layer. Moreover, for the aﬃne transformation, we provide two alternative solutions: interval-based and symbolic-based. The former directly computes sound difference intervals via interval analysis [42], while the latter leverages abstract interpretation [10] to compute sound and symbolic difference intervals, using the polyhedra abstract domain. In comparison, the symbolic-based one is usually more accurate but less eﬃcient than the interval-based one. Note that though existing tools can obtain quantization error intervals by independently computing the output intervals of two networks followed by interval subtractions, such an approach is often too conservative.

To resolve those problems that cannot be proved via our DRA, we resort to the sound and complete MILP-based verification method. Inspired by the MILP encoding of DNN and QNN verification [39,40,68], we propose a novel MILP encoding for verifying quantization error bounds. QEBVerif represents both the computations of the QNN and the DNN in mixed-integer linear constraints which are further simplified using their own output intervals. Moreover, we also encode the output difference intervals of hidden neurons from our DRA as mixed-integer linear constraints to boost the verification.

We implement our method as an end-to-end tool and use Gurobi [20] as our back-end MILP solver. We extensively evaluate it on a large set of verification tasks using neural networks for ACAS Xu [26] and MNIST [31], where the number of neurons varies from 310 to 4890, the number of bits for quantizing weights and activation tensors ranges from 4 to 10 bits, and the number of bits for quantizing inputs is fixed to 8 bits. For DRA, we compare QEBVerif with a naive method that first independently computes the output intervals of DNNs and QNNs using the existing state-of-the-art (symbolic) interval analysis [22,55], and then conducts an interval subtraction. The experimental results show that both our interval- and symbolic-based approaches are much more accurate and can successfully verify much more tasks without the MILP-based verification. We also find that the quantization error interval returned by DRA is getting tighter with the increase of the quantization bit size. The experimental results also confirm the effectiveness of our MILP-based verification method, which can help verify many tasks that cannot be solved by DRA solely. Finally, our results also allow us to study the potential correlation of quantization errors and robustness for QNNs using QEBVerif.

We summarize our contributions as follows:

- We introduce the first sound, complete, and reasonably eﬃcient quantization error bound verification method QEBVerif for fully QNNs by cleverly combining novel DRA and MILP-based verification methods;
- We propose a novel DRA to compute sound and tight quantization error intervals accompanied by an abstract domain tailored to QNNs, which can significantly and soundly tighten the quantization error intervals;
- We implement QEBVerif as an end-to-end open-source tool [64] and conduct an extensive evaluation on various verification tasks, demonstrating its effectiveness and eﬃciency. 

The source code of our tool and benchmarks are available at https://github.com/S3L-offcial/QEBVerif. Missing proofs, more examples, and experimental results can be found in [65].

## Evaluation

We have implemented our method QEBVerif as an end-to-end tool written in Python, where we use Gurobi [20] as our back-end MILP solver. All floating-point numbers used in our tool are 32-bit. Experiments are conducted on a 96-core machine with Intel(R) Xeon(R) Gold 6342 2.80 GHz CPU and 1 TB main memory. We allow Gurobi to use up to 24 threads. The time limit for each verification task is 1 h.

**Benchmarks.** We first build 45 * 4 QNNs from the 45 DNNs of ACAS Xu [26], following a *post-training quantization scheme* [44] and using quantization configurations $\mathcal{C}_{in} = \langle ±, 8, 8 \rangle$, $\mathcal{C}_w = \mathcal{C}_b = \langle ±, Q, Q − 2 \rangle$ , $\mathcal{C}_h = \langle +, Q, Q − 2 \rangle$ , where $Q \in \{4, 6, 8, 10\}$. We then train 5 DNNs with different architectures using the MNIST dataset [31] and build 5 * 4 QNNs following the same quantization scheme and quantization configurations except that we set $\mathcal{C}_{in} = \langle ±, 8, 8 \rangle$ and $\mathcal{C}_w = \langle ±, Q, Q − 1 \rangle$ for each DNN trained on MNIST. 

## Related Work

While there is a large and growing body of work on quality assurance techniques for neural networks including testing (e.g., [4–7,47,50,56,57,63,69]) and formal verification (e.g., [2,8,12,13,15,19,24,29,30,32,34,37,38,51,54,55,58–60, 62,70]). Testing techniques are often effective in finding violations, but they cannot prove their absence. While formal verification can prove their absence, existing methods typically target real-valued neural networks, i.e., DNNs, and are not effective in verifying quantization error bound [48]. In this section, we mainly discuss the existing verification techniques for QNNs.

Early work on formal verification of QNNs typically focuses on 1-bit quantized neural networks (i.e., BNNs) [3,9,46,52,53,66,67]. 

- Narodytska et al. [46] first proposed to reduce the verification problem of BNNs to a satisfiability problem of a Boolean formula or an integer linear programming problem. 
- Baluta et al. [3] proposed a PAC-style quantitative analysis framework for BNNs via approximate SAT model-counting solvers. 
- Shih et al. proposed a quantitative verification framework for BNNs [52,53] via a BDD learning-based method [45]. 
- Zhang et al. [66,67] proposed a BDD-based verification framework for BNNs, which exploits the internal structure of the BNNs to construct BDD models instead of BDD-learning. 
- Giacobbe et al. [16] pushed this direction further by introducing the first formal verification for multiple-bit quantized DNNs (i.e., QNNs) by encoding the robustness verification problem into an SMT formula based on the first-order theory of quantifier-free bit-vector. 
- Later, Henzinger et al. [22] explored several heuristics to improve the efficiency and scalability of [16]. 
- Very recently, [40,68] proposed an ILP-based method and an MILP-based verification method for QNNs, respectively, and both outperform the SMT-based verification approach [22]. 

Though these works can directly verify QNNs or BNNs, they cannot verify quantization error bounds.

There are also some works focusing on exploring the properties of two neural networks which are most closely related to our work. Paulsen et al. [48,49] proposed differential verification methods to verify two DNNs with the same network topology. This idea has been extended to handle recurrent neural networks [41]. The difference between [41,48,49] and our work has been discussed throughout this work, i.e., they focus on quantized weights and cannot handle quantized activation tensors. Moreover, their methods are not complete, thus would fail to prove tighter error bounds. Semi-definite programming was used to analyze the different behaviors of DNNs and fully QNNs [33]. Different from our work focusing on verification, they aim at generating an upper bound for the worst-case error induced by quantization. Furthermore, [33] only scales tiny QNNs, e.g., 1 input neuron, 1 output neuron, and 10 neurons per hidden layer (up to 4 hidden layers). In comparison, our differential reachability analysis scales to much larger QNNs, e.g., QNN with 4890 neurons.

## Conclusion

In this work, we proposed a novel quantization error bound verification method QEBVerif which is sound, complete, and arguably efficient. We implemented it as an end-to-end tool and conducted thorough experiments on various QNNs with different quantization bit sizes. Experimental results showed the effectiveness and the efficiency of QEBVerif. We also investigated the potential correlation between robustness and quantization errors for QNNs and found that as the quantization error increases the QNN might become less robust. For further work, it would be interesting to investigate the verification method for other activation functions and network architectures, towards which this work makes a significant step.

## References

1. Amir, G., Wu, H., Barrett, C.W., Katz, G.: **An SMT-based approach for verifying binarized neural networks**. In: Proceedings of the 27th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, pp. 203–222 (2021)
2. Anderson, G., Pailoor, S., Dillig, I., Chaudhuri, S.: **Optimization and abstraction: a synergistic approach for analyzing neural network robustness**. In: Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 731–744 (2019)
3. Baluta, T., Shen, S., Shinde, S., Meel, K.S., Saxena, P.: **Quantitative verification of neural networks and its security applications**. In: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pp. 1249–1264 (2019)
4. Bu, L., Zhao, Z., Duan, Y., Song, F.: **Taking care of the discretization problem: a comprehensive study of the discretization problem and a black-box adversarial attack in discrete integer domain**. IEEE Trans. Dependable Secur. Comput. 19(5), 3200–3217 (2022)
5. Carlini, N., Wagner, D.A.: **Towards evaluating the robustness of neural networks**. In: Proceedings of the 2017 IEEE Symposium on Security and Privacy, pp. 39–57 (2017)
6. Chen, G., et al.: **Who is real Bob? Adversarial attacks on speaker recognition systems**. In: Proceedings of the 42nd IEEE Symposium on Security and Privacy, pp. 694–711 (2021)
7. Chen, G., Zhao, Z., Song, F., Chen, S., Fan, L., Liu, Y.: **AS2T: arbitrary source-to-target adversarial attack on speaker recognition systems**. IEEE Trans. Dependable Secur. Comput., 1–17 (2022)
8. Chen, G., et al.: **Towards understanding and mitigating audio adversarial examples for speaker recognition**. IEEE Trans. Dependable Secur. Comput., 1–17 (2022)
9. Choi, A., Shi, W., Shih, A., Darwiche, A.: **Compiling neural networks into tractable Boolean circuits**. In: Proceedings of the AAAI Spring Symposium on Verification of Neural Networks (2019)
10. Cousot, P., Cousot, R.: **Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints**. In: Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, pp. 238–252 (1977)
11. Duncan, K., Komendantskaya, E., Stewart, R., Lones, M.: **Relative robustness of quantized neural networks against adversarial attacks**. In: Proceedings of the International Joint Conference on Neural Networks, pp. 1–8 (2020)
12. Ehlers, R.: **Formal verification of piece-wise linear feed-forward neural networks**. In: Proceedings of the 15th International Symposium on Automated Technology for Verification and Analysis, pp. 269–286 (2017)
13. Elboher, Y.Y., Gottschlich, J., Katz, G.: **An abstraction-based framework for neural network verification**. In: Proceedings of the 32nd International Conference on Computer Aided Verification, pp. 43–65 (2020)
14. Eykholt, K., et al.: **Robust physical-world attacks on deep learning visual classification**. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1625–1634 (2018)
15. Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P., Chaudhuri, S., Vechev, M.T.: **AI2: safety and robustness certification of neural networks with abstract interpretation**. In: Proceedings of the IEEE Symposium on Security and Privacy, pp. 3–18 (2018)
16. Giacobbe, M., Henzinger, T.A., Lechner, M.: **How many bits does it take to quantize your neural network?** In: TACAS 2020. LNCS, vol. 12079, pp. 79–97. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-45237-7_5
17. Gong, R., et al.: **Differentiable soft quantization: bridging full-precision and low-bit neural networks**. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 4851–4860 (2019)
18. Google: Tensorflow lite (2022). https://www.tensorflow.org/lite
19. Guo, X., Wan, W., Zhang, Z., Zhang, M., Song, F., Wen, X.: **Eager falsification for accelerating robustness verification of deep neural networks**. In: Proceedings of the 32nd IEEE International Symposium on Software Reliability Engineering, pp. 345–356 (2021)
20. **Gurobi: a most powerful mathematical optimization solver** (2018). https://www.gurobi.com/
21. Han, S., Mao, H., Dally, W.J.: **Deep compression: compressing deep neural network with pruning, trained quantization and Huffman coding**. In: Proceedings of the 4th International Conference on Learning Representations (2016)
22. Henzinger, T.A., Lechner, M., Zikelic, D.: **Scalable verification of quantized neural networks**. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, pp. 3787–3795 (2021)
23. Hinton, G., et al.: **Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups**. IEEE Sig. Process. Mag. 29(6), 82–97 (2012)
24. Huang, X., Kwiatkowska, M., Wang, S., Wu, M.: **Safety verification of deep neural networks**. In: Proceedings of the 29th International Conference on Computer Aided Verification, pp. 3–29 (2017)
25. Jacob, B., et al.: **Quantization and training of neural networks for eﬃcient integer-arithmetic-only inference**. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2704–2713 (2018)
26. Julian, K.D., Kochenderfer, M.J., Owen, M.P.: **Deep neural network compression for aircraft collision avoidance systems**. J. Guid. Control. Dyn. 42(3), 598–608 (2019)
27. Jung, S., et al.: **Learning to quantize deep networks by optimizing quantization intervals with task loss**. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4350–4359 (2019)
28. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Li, F.: **Large-scale video classification with convolutional neural networks**. In: Proceedings of 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1725–1732 (2014)
29. Katz, G., Barrett, C.W., Dill, D.L., Julian, K., Kochenderfer, M.J.: **Reluplex: an eﬃcient SMT solver for verifying deep neural networks**. In: Proceedings of the 29th International Conference on Computer Aided Verification, pp. 97–117 (2017)
30. Katz, G., et al.: **The marabou framework for verification and analysis of deep neural networks**. In: Proceedings of the 31st International Conference on Computer Aided Verification, pp. 443–452 (2019)
31. LeCun, Y., Cortes, C.: **MNIST handwritten digit database** (2010)
32. Li, J., Liu, J., Yang, P., Chen, L., Huang, X., Zhang, L.: **Analyzing deep neural networks with symbolic propagation: towards higher precision and faster verification**. In: Chang, B.-Y.E. (ed.) SAS 2019. LNCS, vol. 11822, pp. 296–319. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-32304-2_15
33. Li, J., Drummond, R., Duncan, S.R.: **Robust error bounds for quantised and pruned neural networks**. In: Proceedings of the 3rd Annual Conference on Learning for Dynamics and Control, pp. 361–372 (2021)
34. Li, R., et al.: **Prodeep: a platform for robustness verification of deep neural networks**. In: Proceedings of the 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1630–1634 (2020)
35. Lin, D.D., Talathi, S.S., Annapureddy, V.S.: **Fixed point quantization of deep convolutional networks**. In: Proceedings of the 33nd International Conference on Machine Learning, pp. 2849–2858 (2016)
36. Lin, J., Gan, C., Han, S.: **Defensive quantization: when eﬃciency meets robustness**. In: Proceedings of the International Conference on Learning Representations (2019)
37. Liu, J., Xing, Y., Shi, X., Song, F., Xu, Z., Ming, Z.: **Abstraction and refinement: towards scalable and exact verification of neural networks**. CoRR abs/2207.00759 (2022)
38. Liu, W., Song, F., Zhang, T., Wang, J.: **Verifying ReLU neural networks from a model checking perspective**. J. Comput. Sci. Technol. 35(6), 1365–1381 (2020)
39. Lomuscio, A., Maganti, L.: **An approach to reachability analysis for feed-forward ReLU neural networks**. CoRR abs/1706.07351 (2017)
40. Mistry, S., Saha, I., Biswas, S.: **An MILP encoding for eﬃcient verification of quantized deep neural networks**. IEEE Trans. Comput.-Aided Des. Integrated Circuits Syst. (Early Access) (2022)
41. Mohammadinejad, S., Paulsen, B., Deshmukh, J.V., Wang, C.: **DiffRNN: differential verification of recurrent neural networks**. In: Proceedings of the 19th International Conference on Formal Modeling and Analysis of Timed Systems, pp. 117–134 (2021)
42. Moore, R.E., Kearfott, R.B., Cloud, M.J.: **Introduction to Interval Analysis**, vol. 110. SIAM (2009)
43. Nagel, M., Amjad, R.A., Van Baalen, M., Louizos, C., Blankevoort, T.: **Up or down? Adaptive rounding for post-training quantization**. In: Proceedings of the International Conference on Machine Learning, pp. 7197–7206 (2020)
44. Nagel, M., Fournarakis, M., Amjad, R.A., Bondarenko, Y., van Baalen, M., Blankevoort, T.: **A white paper on neural network quantization**. arXiv preprint arXiv:2106.08295 (2021)
45. Nakamura, A.: **An eﬃcient query learning algorithm for ordered binary decision diagrams**. Inf. Comput. 201(2), 178–198 (2005)
46. Narodytska, N., Kasiviswanathan, S.P., Ryzhyk, L., Sagiv, M., Walsh, T.: **Verifying properties of binarized deep neural networks**. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp. 6615–6624 (2018)
47. Odena, A., Olsson, C., Andersen, D.G., Goodfellow, I.J.: **TensorFuzz: debugging neural networks with coverage-guided fuzzing**. In: Proceedings of the 36th International Conference on Machine Learning, pp. 4901–4911 (2019)
48. Paulsen, B., Wang, J., Wang, C.: **ReluDiff: differential verification of deep neural networks**. In: 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pp. 714–726. IEEE (2020)
49. Paulsen, B., Wang, J., Wang, J., Wang, C.: **NeuroDiff: scalable differential verification of neural networks using fine-grained approximation**. In: Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 784–796 (2020)
50. Pei, K., Cao, Y., Yang, J., Jana, S.: **DeepXplore: automated whitebox testing of deep learning systems**. In: Proceedings of the 26th Symposium on Operating Systems Principles, pp. 1–18 (2017)
51. Pulina, L., Tacchella, A.: **An abstraction-refinement approach to verification of artificial neural networks**. In: Proceedings of the 22nd International Conference on Computer Aided Verification, pp. 243–257 (2010)
52. Shih, A., Darwiche, A., Choi, A.: **Verifying binarized neural networks by Angluin-style learning**. In: Janota, M., Lynce, I. (eds.) SAT 2019. LNCS, vol. 11628, pp. 354–370. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-24258-9_25
53. Shih, A., Darwiche, A., Choi, A.: **Verifying binarized neural networks by local automaton learning**. In: Proceedings of the AAAI Spring Symposium on Verification of Neural Networks (2019)
54. Singh, G., Ganvir, R., Püschel, M., Vechev, M.T.: **Beyond the single neuron convex barrier for neural network certification**. In: Proceedings of the Annual Conference on Neural Information Processing Systems, pp. 15072–15083 (2019)
55. Singh, G., Gehr, T., Püschel, M., Vechev, M.T.: **An abstract domain for certifying neural networks**. Proc. ACM Program. Lang. (POPL) 3, 41:1–41:30 (2019)
56. Song, F., Lei, Y., Chen, S., Fan, L., Liu, Y.: **Advanced evasion attacks and mitigations on practical ml-based phishing website classifiers**. Int. J. Intell. Syst. 36(9), 5210–5240 (2021)
57. Tian, Y., Pei, K., Jana, S., Ray, B.: **DeepTest: automated testing of deep-neural-network-driven autonomous cars**. In: Proceedings of the 40th International Conference on Software Engineering, pp. 303–314 (2018)
58. Tran, H.-D., Bak, S., Xiang, W., Johnson, T.T.: **Verification of deep convolutional neural networks using ImageStars**. In: Lahiri, S.K., Wang, C. (eds.) CAV 2020. LNCS, vol. 12224, pp. 18–42. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-53288-8_2
59. Tran, H., et al.: **Star-based reachability analysis of deep neural networks**. In: Proceedings of the 3rd World Congress on Formal Methods, pp. 670–686 (2019)
60. Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S.: **Formal security analysis of neural networks using symbolic intervals**. In: Proceedings of the 27th USENIX Security Symposium, pp. 1599–1614 (2018)
61. WikiChip: FSD chip - tesla. https://en.wikichip.org/wiki/tesla_(car_company)/fsd_chip. Accessed 30 Apr 2022
62. Yang, P., et al.: **Improving neural network verification through spurious region guided refinement**. In: Groote, J.F., Larsen, K.G. (eds.) Proceedings of 27th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, pp. 389–408 (2021)
63. Zhang, J.M., Harman, M., Ma, L., Liu, Y.: **Machine learning testing: survey, landscapes and horizons**. IEEE Trans. Software Eng. 48(2), 1–36 (2022)
64. Zhang, Y., Song, F., Sun, J.: QEBVerif (2023). https://github.com/S3L-official/QEBVerif
65. Zhang, Y., Song, F., Sun, J.: QEBVerif: quantization error bound verification of neural networks. CoRR abs/2212.02781 (2023)
66. Zhang, Y., Zhao, Z., Chen, G., Song, F., Chen, T.: **BDD4BNN: a BDD-based quantitative analysis framework for binarized neural networks**. In: Silva, A., Leino, K.R.M. (eds.) CAV 2021. LNCS, vol. 12759, pp. 175–200. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-81685-8_8
67. Zhang, Y., Zhao, Z., Chen, G., Song, F., Chen, T.: **Precise quantitative analysis of binarized neural networks: a BDD-based approach**. ACM Trans. Software Eng. Methodol. 32(3) (2023)
68. Zhang, Y., et al.: **QVIP: an ILP-based formal verification approach for quantized neural networks**. In: Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering, pp. 82:1–82:13 (2023)
69. Zhao, Z., Chen, G., Wang, J., Yang, Y., Song, F., Sun, J.: **Attack as defense: characterizing adversarial examples using robustness**. In: Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 42–55 (2021)
70. Zhao, Z., Zhang, Y., Chen, G., Song, F., Chen, T., Liu, J.: **CLEVEREST: accelerating CEGAR-based neural network verification via adversarial attacks**. In: Singh, G., Urban, C. (eds.) Proceedings of the 29th International Symposium on Static Analysis, pp. 449–473 (2022). https://doi.org/10.1007/978-3-031-22308-2_20